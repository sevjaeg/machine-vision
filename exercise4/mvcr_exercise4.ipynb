{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mvcr_exercise4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cQT6vUuvoQv"
      },
      "source": [
        "# Machine Vision and Cognitive Robotics - Exercise 4\n",
        "\n",
        "<!-- \n",
        "Automation and Control Institute - TU Wien\n",
        "Matthias Hirschmanner 2019\n",
        "machinevision@acin.tuwien.ac.at\n",
        " -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDx1jdP-C4rx"
      },
      "source": [
        "In this exercise you will implement a neural network to classify images of the CIFAR10 dataset (https://www.cs.toronto.edu/~kriz/cifar.html). It consists of 60000 images with a resolution of 32x32. The different classes and example images for each classes are shown in Figure 1 below. We will use the library Keras with the TensorFlow backend to create our neural networks. More specifically, we will use the Functional API of Keras. \n",
        "\n",
        "\n",
        "![Classes of CIFAR10](https://i2.wp.com/appliedmachinelearning.blog/wp-content/uploads/2018/03/cifar2.jpg?resize=427%2C325&ssl=1)\n",
        "\n",
        "Figure 1: Examples of the different classes of the CIFAR10 dataset.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Please keep the code in the sections below clean and only change it in the dedicated areas. You shouldn't need to change it anywhere else. You also shouldn't need to use any additional libraries other than the ones already imported. If you need to change the code somewhere else or need to import a different library to get a functioning program, that might be a bug. Please report it in the Tuwel forum or send us a mail to machinevision@acin.tuwien.ac.at\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NR6xh3rKFDa1"
      },
      "source": [
        "## Import Libraries\n",
        "In a first step we import the libraries needed for the exercise. Please execute the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3ijYWKmK7V7"
      },
      "source": [
        "# Sets the tensorflow version. If you use conda, you might need to delete this line\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "import requests\n",
        "import imageio\n",
        "from PIL import Image\n",
        "\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import callbacks \n",
        "\n",
        "import tensorflow.keras.utils \n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "# Fixes a crash when running on Mac OS\n",
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "\n",
        "get_ipython().__class__.__name__ = \"ZMQInteractiveShell\"\n",
        "\n",
        "print(\"These devices are available. If no GPU shows up in Google Colab, \\\n",
        "change Runtime type to GPU.\")\n",
        "print(device_lib.list_local_devices())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbt_cqeLHFxH"
      },
      "source": [
        "## Load Dataset\n",
        "Next we load the CIFAR10 dataset. The training images are in the numpy array `X_train` and the test images in the numpy array `X_test`. The labels are contained in the numpy arrays `y_train`and `y_test`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb4lbED_HJYA"
      },
      "source": [
        "# Load datasetlassify images of the CI\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Print shape of arrays:\n",
        "print('Training Images Shape:', X_train.shape, 'Data Type:', X_train.dtype)\n",
        "print('Test Images Shape:', X_test.shape)\n",
        "print('Training Labels Shape:', y_train.shape)\n",
        "print('Test Labels Shape:', y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zd0dC8E4Eh7s"
      },
      "source": [
        "## Plot random images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5V66YLArMm2S",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell!\n",
        "#@markdown It will show you 9 random images of the dataset. \n",
        "#@markdown The code itself is not relevant, but it is important for later to execute this cell because some plotting functions are defined here. \n",
        "fig, axs = plt.subplots(3, 3,figsize=(10,10))\n",
        "labels = {0:'airplane',1:'automobile',2:'bird',3:'cat',4:'deer',5:'dog',6:'frog',7:'horse',8:'ship',9:'truck'}\n",
        "random_indices = np.random.randint(X_test.shape[0], size=9)\n",
        "for (idx,ax) in zip(random_indices,axs.flat):\n",
        "  ax.set_title(labels[y_test[idx,0]])\n",
        "  ax.imshow(X_test[idx])\n",
        "  \n",
        "#Function to plot the training\n",
        "def plot_history(history):\n",
        "\n",
        "  # Plot the Training History\n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,5))\n",
        "  fig.suptitle('MLP Training')\n",
        "  ax1.plot(history.history['accuracy'], label=\"Train\")\n",
        "  ax1.plot(history.history['val_accuracy'], label=\"Test\")\n",
        "  ax1.set(xlabel='Epoch', ylabel='Accuracy')\n",
        "  ax1.legend(loc=\"upper left\")\n",
        "  ax2.plot(history.history['loss'], label='Train')\n",
        "  ax2.plot(history.history['val_loss'], label='Test')\n",
        "  ax2.set(xlabel='Epoch', ylabel='Loss')\n",
        "  ax2.legend(loc=\"upper right\")\n",
        "\n",
        "\n",
        "#Function corect/wrong recognition:\n",
        "def plot_predictions(data, model_name, class_name=None):\n",
        "  labels = {0:'airplane',1:'automobile',2:'bird',3:'cat',4:'deer',5:'dog',6:'frog',7:'horse',8:'ship',9:'truck'}\n",
        "  labels_inv = {v: k for k, v in labels.items()}\n",
        "  y_predictions = model_name.predict(data) \n",
        "\n",
        "  # Get the predicted labels [0,9]\n",
        "  y_predictions_labels = np.argmax(y_predictions,axis=1)\n",
        "  y_predictions[y_predictions<0.5]=0 # prediction rate R\n",
        "\n",
        "# getting a list of ALL images and labels with predicion rate R \n",
        "  out_ind = np.nonzero(y_predictions) # index of non zero\n",
        "  out_ind_label = out_ind[1] # index of a label 0-9\n",
        "  out_ind_image = out_ind[0] # index of an image 0...N (N - size of dataset)\n",
        "  out_images = X_test[out_ind_image]\n",
        "# getting lists of ONLY correct and wrong predicted images\n",
        "  true_out_ind = out_ind[0][y_test[out_ind[0]][:,0] == out_ind_label]\n",
        "  wrong_out_ind = out_ind[0][y_test[out_ind[0]][:,0] != out_ind_label]\n",
        "# check if class_name defined at all  (1.'if' if class_name defined, 2.'if' if class_name from the labels list)\n",
        "  if class_name:\n",
        "    class_number = labels_inv.get(class_name, -1)\n",
        "    if class_number != -1: # taking only predictions with defined class_name \n",
        "\n",
        "      # Images that were correctly predicted with class_name\n",
        "      true_out_ind = true_out_ind[y_predictions_labels[true_out_ind]==class_number]\n",
        "      \n",
        "      # Images that are part of class_name, but were wrongly predicted\n",
        "      false_positive_ind = wrong_out_ind[y_predictions_labels[wrong_out_ind]==class_number]\n",
        "\n",
        "      # Images that are part of class_name but were wrongly predicted\n",
        "      false_negative_ind = wrong_out_ind[y_test[wrong_out_ind][:,0]==class_number]\n",
        "      print('Number of correct recognized', class_name, 'images is', len(true_out_ind))\n",
        "      print('Number of images recognized as', class_name, 'but are not of that class is', len(false_positive_ind))\n",
        "      print('Number of images not recognized as', class_name, 'but actually are of that class is', len(false_negative_ind))\n",
        "\n",
        "    else:\n",
        "      print('No such class like', class_name + '. Check class name again.')\n",
        "  else:  \n",
        "    print('Number of correct recognized images is', len(true_out_ind))\n",
        "    print('Number of wrong recognized images is', len(wrong_out_ind))\n",
        "# plot of 10 correct and 10 wrong random recognized images \n",
        "  true_ind_plot = random.sample(list(true_out_ind), k=10) # correct\n",
        "  wrong_ind_plot = random.sample(list(wrong_out_ind), k=10) # wrong\n",
        "  if class_name:\n",
        "    if class_number != -1:\n",
        "      fig = plt.figure(figsize=(20,7.5))\n",
        "\n",
        "      if len(false_positive_ind) > 10:\n",
        "        false_positive_ind_plot = random.sample(list(false_positive_ind), k=10) # wrong\n",
        "      else:\n",
        "        false_positive_ind_plot = false_positive_ind\n",
        "      \n",
        "      if len(false_negative_ind) > 10:\n",
        "        false_negative_ind_plot = random.sample(list(false_negative_ind), k=10) # wrong\n",
        "      else:\n",
        "        false_negative_ind_plot = false_negative_ind\n",
        "\n",
        "      for idx, image_idx in enumerate(true_ind_plot):\n",
        "        a = fig.add_subplot(3, 10, idx+1)\n",
        "        imgplot = plt.imshow(X_test[image_idx])\n",
        "        a.set_title(labels[y_predictions_labels[image_idx]], color='green', y=-0.2)\n",
        "        a.axis('off')\n",
        "      for idx, image_idx in enumerate(false_positive_ind_plot):\n",
        "        a = fig.add_subplot(3, 10, idx+11)\n",
        "        imgplot = plt.imshow(X_test[image_idx])\n",
        "        a.set_title(labels[y_predictions_labels[image_idx]], color='red', y=-0.2)\n",
        "        a.axis('off')\n",
        "        a.set_xlabel(labels[y_predictions_labels[image_idx]], color='red')\n",
        "      for idx, image_idx in enumerate(false_negative_ind_plot):\n",
        "        a = fig.add_subplot(3, 10, idx+21)\n",
        "        imgplot = plt.imshow(X_test[image_idx])\n",
        "        a.set_title(labels[y_predictions_labels[image_idx]], color='red', y=-0.2)\n",
        "        a.axis('off')\n",
        "      plt.figtext(0.5,0.9, \"Correct Predictions\", ha=\"center\", va=\"top\", fontsize=14)\n",
        "      plt.figtext(0.5,0.63, \"False Positives\", ha=\"center\", va=\"top\", fontsize=14)\n",
        "      plt.figtext(0.5,0.36, \"False Negatives\", ha=\"center\", va=\"top\", fontsize=14)\n",
        "\n",
        "  else:\n",
        "    fig = plt.figure(figsize=(20,5))\n",
        "    for idx, image_idx in enumerate(true_ind_plot):\n",
        "      a = fig.add_subplot(2, 10, idx+1)\n",
        "      imgplot = plt.imshow(X_test[image_idx])\n",
        "      a.set_title(labels[y_predictions_labels[image_idx]], color='green')\n",
        "    for idx, image_idx in enumerate(wrong_ind_plot):\n",
        "      a = fig.add_subplot(2, 10, idx+11)\n",
        "      imgplot = plt.imshow(X_test[image_idx])\n",
        "      a.set_title(labels[y_predictions_labels[image_idx]], color='red')\n",
        "\n",
        "\n",
        "# Normalization of an image and training\n",
        "def predict_image(nn_model, image):\n",
        "  labels = {0:'airplane',1:'automobile',2:'bird',3:'cat',4:'deer',5:'dog',6:'frog',7:'horse',8:'ship',9:'truck'}\n",
        "  # prediction with a model\n",
        "  test_prediction = nn_model.predict(image) # define a model of nn\n",
        "  print(test_prediction)\n",
        "  # top 5 predictions\n",
        "  out_ind_up = sorted(range(len(list(test_prediction[0]))), key = lambda sub: test_prediction[0][sub])[-5:] \n",
        "  # result\n",
        "  print(\"Top-5 Predictions:\")\n",
        "  for i in out_ind_up[::-1]:\n",
        "    print(' ', labels[i].capitalize(), '-', round((test_prediction[0][i])*100,2), '%') \n",
        "  \n",
        "# Load an image from an external URL an returns it\n",
        "def load_image_link(link): \n",
        "  response = requests.get(link)\n",
        "  im_from_link = Image.fromarray(imageio.imread((response.content))) \n",
        "  # Adjust width and height to CIFAR10 resolution\n",
        "  width = 32\n",
        "  height = 32\n",
        "  loaded_image = im_from_link.resize((width, height), Image.ANTIALIAS)\n",
        "  loaded_image = np.expand_dims(loaded_image, axis = 0)\n",
        "  return loaded_image\n",
        "\n",
        "# Load an image from Colab folder\n",
        "def load_image_colab(image_name): \n",
        "  # Default Colab folder: \"/content/...\"\n",
        "  imageFile = \"/content/\" + image_name # taking a file with original size\n",
        "  im_from_fold = Image.open(imageFile) # if you do it from colab folder\n",
        "  # Adjust width and height to CIFAR10 resolution\n",
        "  width = 32\n",
        "  height = 32\n",
        "  loaded_image = np.array(im_from_fold.resize((width, height), Image.ANTIALIAS))\n",
        "  loaded_image = np.expand_dims(loaded_image, axis = 0)\n",
        "  return loaded_image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0ougqf4RIP4"
      },
      "source": [
        "## Normalize Images (1 Point)\n",
        "Your first task is to create the function `normalize_images` which takes the training images `X_train` and the test images `X_test` as parameters. The outputs should be the two normalized sets with the shape `(dataset_size, 32, 32, 3)` and data type `np.float32`. Normalize in a way, that the returned arrays have approximately zero mean ($\\mu=0$) and unit variance ($\\sigma=1$). You can decide if you want to normalize per color channel or over the whole dataset. Only use the standard numpy functionality to implement this function (e.g. `np.mean()` and `np.var()`)\n",
        "\n",
        "**IMPORTANT:** Use the same mean and and standard deviation you get from the training set also for the test set, because we want our training and test data to go through the same transformation.\n",
        "\n",
        "You can find more detailed explanation of why we do normalization in this video by Andrew Ng: [Andrew Ng - Normalizing Inputs](https://www.youtube.com/watch?v=FDCfw-YqWTE)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT_cUGjk6wmn"
      },
      "source": [
        "def normalize_images(training_images: np.ndarray, \n",
        "                     test_images: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
        "  \"\"\" Normalize training and test images to have zero mean and unit variance\n",
        "\n",
        "  :param training_images: The training images\n",
        "  :type training_images: np.ndarray with shape (train_batch_size, width, height, channels)\n",
        "    and dtype = np.uint8 and values in the range [0, 255]\n",
        "\n",
        "  :param test_images: The test images\n",
        "  :type test_images: np.ndarray with shape (test_batch_size, width, height, channels)\n",
        "    with dtype = np.uint8 and values in the range [0, 255]\n",
        "  \n",
        "  :return: (normalized_training_images, normalized_test_images)\n",
        "    normalized_training_images: Normalized training images with zero mean and unit variance\n",
        "  :rtype: Tuple(normalized_training_images, normalized_test_images)\n",
        "    normalized_training_images: np.ndarray with shape (train_batch_size, width, height, channels)\n",
        "      and dtype = np.float32\n",
        "    normalized_test_images: np.ndarray with shape (test_batch_size, width, height, channels)\n",
        "      and dtype = np.float32\n",
        "  \"\"\"\n",
        "  ########## Fix This Part ##########\n",
        "  \n",
        "  normalized_training_images = np.zeros(training_images.shape)\n",
        "  normalized_test_images = np.zeros(test_images.shape)\n",
        "  \n",
        "  ###################################\n",
        "\n",
        "  return normalized_training_images, normalized_test_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdFEhjMyoMlD"
      },
      "source": [
        "## Preprocess labels (1 Point)\n",
        "Keras needs the labels as an one-hot encoded vector for training. The function `preprocess_labels(labels, no_of_classes)` should take a label with shape `(batch_size, 1)`, an integer with the number of classes and create a one-hot encoded numpy array with the shape `(batch_size, number_of_classes)`. Keras has the built-in function `tensorflow.keras.utils.to_categorical` which creates this vector for us. For this exercise, don't use it or similar functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YF2ptMmpGoT"
      },
      "source": [
        "def preprocess_labels(labels: np.ndarray, \n",
        "                      no_of_classes: int) -> np.ndarray:\n",
        "  \"\"\" Return one-hot encoded labels\n",
        "\n",
        "  :param labels: Labels for each training/test image as a number in the range [0, number_of_classes - 1]\n",
        "  :type labels: np.ndarray with shape (batch_size, 1) and dtype = np.uint8\n",
        "\n",
        "  :param no_of_classes: Number of classes in the dataset\n",
        "  :type no_of_classes: int\n",
        "\n",
        "  :return output_labels: The one-hot encoded labels. Each label is a vector with \n",
        "    all entries = 0 and a single entry = 1 at the index of the correct class. \n",
        "  :rtype: np.ndarray with shape (batch_size, 10) with dtype = np.float32\n",
        "  \"\"\"\n",
        "  ########## Fix This Part ##########\n",
        "  \n",
        "  output_labels = np.zeros((labels.shape[0], no_of_classes))  \n",
        "\n",
        "\n",
        "  ###################################\n",
        "  \n",
        "  return output_labels\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt-ZhBc89YBn"
      },
      "source": [
        "The next cell tests your function with the built-in function of Keras:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_finaHV9aX2"
      },
      "source": [
        "y_train_onehot = preprocess_labels(y_train, 10)\n",
        "y_test_onehot = preprocess_labels(y_test, 10)\n",
        "if((y_train_onehot == tensorflow.keras.utils.to_categorical(y_train, 10)).all() \n",
        "  and (y_test_onehot == tensorflow.keras.utils.to_categorical(y_test,10)).all()):\n",
        "  print(\"Test Successful!\")\n",
        "else:\n",
        "  print(\"Something went wrong, check your preprocess_labels function\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f8alqJYMUNT"
      },
      "source": [
        "##Loss Function (1 Point)\n",
        "We need a loss function to perform the actual training of our model. Implement the cross-entropy loss with the mathematical functions defined in keras.backend. The function `my_crossentropy_loss` should take the input tensor `y_true` with the one-hot-encoded training labels and the predictions of our network `y_pred` which is a tensor of the same dimensions with the softmax prediction values for each class (between 0 and 1). The shape of the input tensors is `(number_of_predictions, number_of_classes)` and the shape of the output tensor should be `(number_of_predictions,)`. You should use the functions provided in the Keras backend e.g. `K.sum()` (https://www.tensorflow.org/api_docs/python/tf/keras/backend/sum). Don't use the built-in crossentropy loss of Keras. For an example check the code snippet below. The cross-entropy loss is defined as \n",
        "\\begin{equation}\n",
        "L(\\mathbf{y},\\mathbf{\\hat{y}})=-\\sum_{k=1}^{K}y_{k}\\log(\\hat{y}_{k}).\n",
        "\\end{equation}\n",
        "\n",
        "This video gives a good explanation about the cross-entropy loss: https://youtu.be/ueO_Ph0Pyqk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaRPkQu5Noy2"
      },
      "source": [
        "def my_crossentropy_loss(y_true: tf.Tensor, \n",
        "                         y_pred: tf.Tensor) -> tf.Tensor:\n",
        "  \"\"\" Calculate the categorical crossentropy loss between the labels and the prediction\n",
        "\n",
        "  :param y_true: One-hot encoded training labels\n",
        "  :type y_true: tf.Tensor with shape (batch_size, num_classes) and dtype = np.float32\n",
        "\n",
        "  :param y_pred: Prediction values of classes in the range [0, 1]\n",
        "  :type y_pred: tf.Tensor with shape (batch_size, num_classes) and dtype = np.float32\n",
        "\n",
        "  :return: Categorical crossentropy loss\n",
        "  :rtype: tf.Tensor with shape (batch_size,) and dtype = np.float32\n",
        "  \"\"\"\n",
        "  ########## Fix This Part ##########\n",
        "\n",
        "  loss = K.constant([0.,0.,0.],shape=[1,3])\n",
        "  \n",
        "\n",
        "  ###################################\n",
        "  \n",
        "  return loss\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiXy5edN9Gkf"
      },
      "source": [
        "You can check your implementation by comparing it to the built-in function of Keras. In the example below we have the prediction and true_labels of 4 images with 3 classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzeJVsQv9CjI"
      },
      "source": [
        "\n",
        "label_tensor = K.constant([1., 0., 0., \\\n",
        "                           0., 1., 0., \\\n",
        "                           0., 0., 1., \\\n",
        "                           0., 0., 1.], shape=[4,3])\n",
        "\n",
        "prediction_tensor = K.constant([.9,  .05, .05, \\\n",
        "                                .05, .89, .06, \\\n",
        "                                .5,  .4,  .1,  \\\n",
        "                                .01, .01, .98], shape=[4,3])\n",
        "\n",
        "my_crossentropy_output = my_crossentropy_loss(label_tensor, prediction_tensor)\n",
        "keras_crossentropy_output = K.categorical_crossentropy(label_tensor, prediction_tensor)\n",
        "\n",
        "print('Input shape: ', label_tensor.shape, ' Output Shape: ', my_crossentropy_output.shape)\n",
        "print('My Crossentropy Loss:    ', K.eval(my_crossentropy_output))\n",
        "print('Keras built-in function: ', K.eval(keras_crossentropy_output))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-51E4dTAxP9I"
      },
      "source": [
        "## Linear Classifier (1 Point)\n",
        "In a first Step we want to train a simple network with only one layer (no hidden layers). A dense layer takes each input value (each pixel intensity) multiplies it with a weight and adds a bias term for each output neuron. An animation of the process is shown here: https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#3\n",
        "\n",
        "To be able to feed the images to the network, we need to reshape them to a vector. The function `vectorize_images(images)` takes as input parameter our images as a `numpy.array` with the shape `(batch_size, height, width, color_channels)` and returns a `numpy.array` with the shape `(batch_size, input_dim)`. You can use the function `np.reshape()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEiA3GGpqrTZ"
      },
      "source": [
        "def vectorize_images(images: np.ndarray) -> np.ndarray:\n",
        "  \"\"\" Reshape images to a one-dimensional vectors\n",
        "\n",
        "  :param images: The input images to be normalized\n",
        "  :type images: np.ndarray with shape (batch_size, height, width, color_channels)\n",
        "\n",
        "  :return: The images as one-dimensional arrays\n",
        "  :rtype: np.ndarray with shape (batch_size, height * width * color_channels)\n",
        "    and the same datatype as the input images\n",
        "  \"\"\"\n",
        "  ########## Fix This Part ##########\n",
        "  images_vector = np.array([])\n",
        "\n",
        "  ###################################\n",
        "\n",
        "  return images_vector\n",
        "\n",
        "\n",
        "# First normalize our training and test images\n",
        "X_train_normalized, X_test_normalized = normalize_images(X_train, X_test)\n",
        "\n",
        "# Now use vectorize_images to create our vectors\n",
        "X_train_vector = vectorize_images(X_train_normalized)\n",
        "X_test_vector = vectorize_images(X_test_normalized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbnvgvluIx_T"
      },
      "source": [
        "To create the model please use the functional API of Keras since it is more flexible than the sequential model: https://keras.io/getting-started/functional-api-guide/ \n",
        "\n",
        "In this part, you should only need to change the arguments of the functions. You can keep the general structure as it is. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49FC7briIwdj"
      },
      "source": [
        "########## Fix This Part ##########\n",
        "\n",
        "#TODO: Please only change the parameters here\n",
        "\n",
        "# This returns a tensor\n",
        "inputs = layers.Input() #TODO: Fix the parameters\n",
        "\n",
        "# A layer instance is callable on a tensor, and returns a tensor\n",
        "output_layer = layers.Dense()(inputs) #TODO: Fix the parameters\n",
        "\n",
        "###################################\n",
        "\n",
        "\n",
        "# This creates a model that includes\n",
        "# the Input layer and one Dense layer\n",
        "one_layer_model = Model(inputs=inputs,\n",
        "                        outputs=output_layer)\n",
        "\n",
        "# We compile our model with the Stochastic Gradient Descent as optimizer\n",
        "# and the cross-entropy loss we implemented earlier\n",
        "one_layer_model.compile(optimizer='sgd',\n",
        "              loss=my_crossentropy_loss, \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "one_layer_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pImG7r3LsCop"
      },
      "source": [
        "### Actual Training\n",
        "This command starts the actual training. Make sure you selected the hardware accelarator GPU in Runtime -> Change Runtime type. One epoch should take below 10 seconds.\n",
        "\n",
        "Run the training for about 30 epochs which should get you to >30% validation accuracy. If the model doesn't go above ~10% (random guessing), check your normalization and the activation function of the `output_layer`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwbP6tRRsAwA"
      },
      "source": [
        "history_one_layer=one_layer_model.fit(x=X_train_vector, \n",
        "                                      y=y_train_onehot, \n",
        "                                      validation_data=(X_test_vector, y_test_onehot), \n",
        "                                      epochs=30)  # starts training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJMoPutW1H62"
      },
      "source": [
        "We can also plot the the training process. Think a bit about what you are seeing here (you will also need to write about it for the documentation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq5BnZDrsG82"
      },
      "source": [
        "plot_history(history_one_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFIi-9KkCIoz"
      },
      "source": [
        "We can also have a look at some predictions of our model of the test set. The function `plot_predictions(data, model_name, class_name=None)` plots predictions of of random images of the test set with our model. The input data should be X_test preprocessed as the model expects it. By specifying the optional parameter class_name, only correct predictions, false positives and false negatives of this class will be plotted. Feel free to change the parameters below. In the image below you can see an example output of the function with the `class_name='horse'` for a different model.\n",
        "\n",
        "![alt text](https://owncloud.tuwien.ac.at/index.php/apps/files_sharing/ajax/publicpreview.php?x=1680&y=730&a=true&file=horse_prediction_mlpreg.png&t=0w2rKhrCgTDlMmb&scalingup=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzdslAn2CHMN"
      },
      "source": [
        "plot_predictions(X_test_vector, one_layer_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVK-kkVbCnw4"
      },
      "source": [
        "plot_predictions(X_test_vector, one_layer_model, class_name='ship')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlJxFwf61P_G"
      },
      "source": [
        "## Multilayer Perceptron (1 Point)\n",
        "The last model with only one layer reached appr. 30% of validation accuracy. It is already better than random guessing but not really satisfactory. Now it's time to add the \"Deep\" to Deep Learning. Create a model with multiple dense layers (a multilayer perceptron) with ReLu activation in the hidden layers and train it again for about 30 Epochs. The exact structure of the model is up to you, a good starting point is a layer with 256 units, followed by another layer with 128 units and followed by the output layer. This model should reach around 50% of validation accuracy. Training time is dependent on your model but should be below 20s per epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDNJcpHay2Sz"
      },
      "source": [
        "########## Fix This Part ##########\n",
        "\n",
        "# This returns a tensor\n",
        "mlp_inputs = layers.Input()\n",
        "\n",
        "# a layer instance is callable on a tensor, and returns a tensor\n",
        "mlp_predictions = layers.Dense()()\n",
        "\n",
        "###################################\n",
        "\n",
        "\n",
        "mlp_model = Model(inputs = mlp_inputs, outputs = mlp_predictions)\n",
        "mlp_model.compile(optimizer = 'sgd',\n",
        "              loss='categorical_crossentropy', # We now use the built-in categorical_crossentropy loss\n",
        "              metrics=['accuracy'])\n",
        "history_mlp=mlp_model.fit(x = X_train_vector, \n",
        "                          y = y_train_onehot, \n",
        "                          validation_data = (X_test_vector, y_test_onehot), \n",
        "                          epochs = 30)  # starts training\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeKtclOi5Yv1"
      },
      "source": [
        "Time again to plot the training. You should now see the effect of overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T31Ikvu2476M"
      },
      "source": [
        "plot_history(history_mlp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDCNQQhX-EbG"
      },
      "source": [
        "## MLP with Regularization (1 Point)\n",
        "To counter the problem of overfitting, you should add measures for regularization. Create a new model based on your MLP from the last point which includes at least one regularization technique. It should improve the validation accuracy slightly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDhRl2kB-VrH"
      },
      "source": [
        "########## Fix This Part ##########\n",
        "\n",
        "mlpreg_inputs = layers.Input()\n",
        "\n",
        "mlpreg_predictions = layers.Dense()()\n",
        "\n",
        "###################################\n",
        "\n",
        "mlpreg_model = Model(inputs = mlpreg_inputs, outputs = mlpreg_predictions)\n",
        "\n",
        "# We save the weights here before training to reset them in the experiments part later\n",
        "mlpreg_model.save_weights('mlpreg_model_weights.h5') \n",
        "\n",
        "mlpreg_model.compile(optimizer = 'sgd',\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "mlpreg_model.summary()\n",
        "history_mlpreg = mlpreg_model.fit(x = X_train_vector, \n",
        "                          y = y_train_onehot, \n",
        "                          validation_data = (X_test_vector, y_test_onehot), \n",
        "                          epochs = 30)  # starts training\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwvOV3aPT0EQ"
      },
      "source": [
        "Let's plot the training process again. If the overfitting is not solved, add additional regularization techniques."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xJTJRB_T5oG"
      },
      "source": [
        "plot_history(history_mlpreg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUyKM45o2vEt"
      },
      "source": [
        "We can again plot some predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvh8EUxB4fXo"
      },
      "source": [
        "plot_predictions(X_test_vector, mlpreg_model, class_name=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEI8s7b1pLIb"
      },
      "source": [
        "## Convolutional Neural Network (2 Points)\n",
        "When converting our images to vectors, all spatial information is lost. A convolutional neural network takes matrices (tensors to be more precise) as input and computes features which make use of spatial information. In this exercise implement a neural network as specified in the image below. Add regularization techniques until you reach at least 75% of validation accuracy with a training time of below 30s per epoch.\n",
        "\n",
        "Notes: 3x3 Conv X means a Conv2D layer with kernel 3x3 and X units. \n",
        "Maxpool /2 means a MaxPool layer with kernel=(2,2) and stride=2.\n",
        "\n",
        "\n",
        "![Network Architecture](https://owncloud.tuwien.ac.at/index.php/apps/files_sharing/ajax/publicpreview.php?x=3360&y=1178&a=true&file=CNN-architecture.png&t=Ms797G0SEXgeZZe&scalingup=0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiQY-73LUst8"
      },
      "source": [
        "X_train_normalized, X_test_normalized = normalize_images(X_train,X_test)\n",
        "\n",
        "########## Fix This Part ##########\n",
        "\n",
        "cnn_inputs = layers.Input()\n",
        "\n",
        "cnn_predictions = layers.Dense()()\n",
        "\n",
        "###################################\n",
        "\n",
        "cnn_model = Model(inputs=cnn_inputs, outputs=cnn_predictions)\n",
        "\n",
        "# We use the Adam optimizer here which uses more complex methods than our standard SGD\n",
        "cnn_model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "cnn_model.summary()\n",
        "history_cnn=cnn_model.fit(x=X_train_normalized, \n",
        "                          y=y_train_onehot, \n",
        "                          validation_data=(X_test_normalized, y_test_onehot), \n",
        "                          epochs=30)  # starts training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xmy9YBUbHu8Q"
      },
      "source": [
        "Plot the training again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPucWVR575yy"
      },
      "source": [
        "plot_history(history_cnn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwylZP6OH0ok"
      },
      "source": [
        "We can again plot some predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRhGb3xnH2mD"
      },
      "source": [
        "plot_predictions(X_test_normalized, cnn_model, class_name=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiyDYnGbQhUE"
      },
      "source": [
        "##Finetuning (2 Points)\n",
        "In the next step we want to use a model which is already pretrained on a large dataset (Imagenet) and finetune it for the CIFAR10 dataset. Keras already provides us with multiple pretrained models (see https://keras.io/applications/). Your task is to take the ResNet50 model and **only** retrain the last layer. You should upsample the images first because ResNet is trained on Images with the resolution of (224, 224). However training with this resolution takes very long with not that much gain. A resolution of (128, 128) is a good compromise between accuracy and training time. You can use the `UpSampling2D` layer of Keras. You should also preprocess the images the same way as ResNet using the function `preprocess_input` from the ResNet50 library. This approach should get you to over 80% of validation accuracy. Training time will take much longer here (~120 seconds per epoch), so we will only train for 5 epochs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNCxAooPY2h7"
      },
      "source": [
        "from tensorflow.keras.applications.resnet import ResNet50, preprocess_input\n",
        "\n",
        "\n",
        "########## Fix This Part ##########\n",
        "\n",
        "X_train_resnet = np.zeros((10,32,32,3))\n",
        "X_test_resnet = np.zeros((10,32,32,3))\n",
        "\n",
        "resnet_input = layers.Input()\n",
        "resnet_predictions = layers.Dense()()\n",
        "\n",
        "###################################\n",
        "\n",
        "resnet_model = Model(inputs=resnet_input, outputs=resnet_predictions)\n",
        "resnet_model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "resnet_model.summary()\n",
        "history_resnet=resnet_model.fit(x=X_train_resnet, \n",
        "                          y=y_train_onehot, \n",
        "                          validation_data=(X_test_resnet, y_test_onehot),\n",
        "                          epochs=5)  # starts training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSigJ5Ls775C"
      },
      "source": [
        "plot_history(history_resnet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzDdwyTAZWh0"
      },
      "source": [
        "# Experiments\n",
        "Here you can add code that you need for your documentation. Feel free to play around in this section with the models, your own images, create new models, data augmentation, different datasets, ...\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R01lKCdIrfb_"
      },
      "source": [
        "# Create an optimizer and then reload weights we saved earlier.\n",
        "my_sgd = optimizers.SGD()\n",
        "mlpreg_model.load_weights('my_model_weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETFyO0HRZYbG"
      },
      "source": [
        "# Load an image from that link and get Top-5 predictions\n",
        "test_im = load_image_link('https://www.telegraph.co.uk/content/dam/news/2019/01/12/TELEMMGLPICT000185347942_trans_NvBQzQNjv4Bq4k9pB6mVv575RZMUuuHUNjlaTMTxUhlzF8Rkw038U-A.jpeg?imwidth=1400')\n",
        "plt.imshow(test_im[0,...])\n",
        "test_im = normalize_images(X_train, test_im)[1]\n",
        "vec_im = vectorize_images(test_im)\n",
        "predict_image(one_layer_model, vec_im)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XTowBsoD_lB"
      },
      "source": [
        "# If you want to mount your Google Drive to store weights or plots for example\n",
        "# you can use the commands below. Check this link for more information:\n",
        "# https://colab.research.google.com/notebooks/io.ipynb#scrollTo=u22w3BFiOveA\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}